#### [KNN算法](https://www.cnblogs.com/erbaodabao0611/p/7588840.html)

##### 基本思路
如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，
##### 算法流程
1. 计算测试数据与各个训练数据之间的距离(欧式距离/曼哈顿距离等等)
2. 按照距离的递增关系进行排序
3. 选取距离最小的K个点
4. 确定前K个点所在类别的出现频率
5. 返回前K个点中出现频率最高的类别作为测试数据的预测分类

##### 特点
1. 惰性学习: KNN没有训练阶段
2. 复杂度较高: 新样本需要与数据集中的每个数据计算距离, 复杂度和数据条目n成正比. 时间复杂度为O(n)
3. 依赖K的取值： K取值不同, 分类结果可能不同, K通常是不大于20的整数